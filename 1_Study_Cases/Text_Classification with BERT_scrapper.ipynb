{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with BERT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Instalando as dependências necessárias\n",
    "# ! pip install -q pandas\n",
    "# ! pip3 install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# ! pip install -q transformers\n",
    "# # ! pip install torchviz\n",
    "# ! pip install -q scikit-learn\n",
    "# ! pip install -q ipywidgets\n",
    "# # Tratamento de dados\n",
    "# ! pip install -U -q pip setuptools wheel\n",
    "# ! pip install -U -q spacy\n",
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando dependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baixar CSV DAtaset\n",
    "\n",
    "Usar o dataset obtido por meio do scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"D:/tcc2/guilherme/1_Exemplos_estudos/data/IMDB Dataset.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[['review','sentiment']]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(ignore_index=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"value counts df['sentiment']:\")\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o número de linhas desejado para cada categoria\n",
    "num_rows_per_category = {\n",
    "    \"1\": 2000,\n",
    "    \"2\": 2000,\n",
    "    \"3\": 2000,\n",
    "    \"4\": 2000,\n",
    "    \"5\": 3745,\n",
    "    \"6\": 4255,\n",
    "    \"7\": 2000,\n",
    "    \"8\": 2000,\n",
    "    \"9\": 2000,\n",
    "    \"10\": 2000,\n",
    "}\n",
    "\n",
    "# Lista para armazenar os DataFrames de cada categoria\n",
    "dfs = []\n",
    "\n",
    "# Iterar sobre cada categoria\n",
    "for rating, group in df.groupby(\"rating\"):\n",
    "    rating_str = str(rating)  # Convertendo para string\n",
    "    num_samples = min(num_rows_per_category[rating_str], len(group))\n",
    "# Selecionar aleatoriamente o número correto de linhas para cada categoria\n",
    "    sampled_rows = group.sample(n=num_samples, random_state=42)\n",
    "# Adicionar os dados selecionados à lista\n",
    "    dfs.append(sampled_rows)\n",
    "\n",
    "\n",
    "# Concatenar os DataFrames de cada categoria em um único DataFrame\n",
    "balanced_df = pd.concat(dfs)\n",
    "\n",
    "# Mostrar as primeiras linhas do DataFrame balanceado\n",
    "print(balanced_df.head())\n",
    "\n",
    "# Verificar se as categorias estão balanceadas\n",
    "print(balanced_df[\"rating\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_rating(rating):\n",
    "    if int(rating) <= 4:\n",
    "        return 0\n",
    "    elif int(rating) <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"rating\"] = balanced_df[\"rating\"].apply(categorize_rating)\n",
    "print(balanced_df[\"rating\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defina o número de linhas desejado para cada categoria\n",
    "# num_rows_per_category = {\n",
    "#     0: 8000,\n",
    "#     1: 8000,\n",
    "#     2: 8000\n",
    "# }\n",
    "\n",
    "# # Lista para armazenar os DataFrames de cada categoria\n",
    "# dfs = []\n",
    "\n",
    "# # Iterar sobre cada categoria\n",
    "# for rating, group in balanced_df.groupby(\"rating\"):\n",
    "#     # rating_str = str(rating)  # Convertendo para string\n",
    "#     num_samples = min(num_rows_per_category[rating], len(group))\n",
    "#     # Selecionar aleatoriamente o número correto de linhas para cada categoria\n",
    "#     sampled_rows = group.sample(n=num_samples, random_state=42)\n",
    "#     # Adicionar os dados selecionados à lista\n",
    "#     dfs.append(sampled_rows)\n",
    "\n",
    "# # Concatenar os DataFrames de cada categoria em um único DataFrame\n",
    "# balanced_df = pd.concat(dfs)\n",
    "\n",
    "# # Mostrar as primeiras linhas do DataFrame balanceado\n",
    "# print(balanced_df.head(), \"\\n\")\n",
    "# # Verificar se as categorias estão balanceadas\n",
    "# print(balanced_df[\"rating\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"review\"].tolist()\n",
    "labels = df[\"rating\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts_labels(df):\n",
    "    texts = df[\"review\"].tolist()\n",
    "    labels = df[\"rating\"].tolist()\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maior_text(texts):\n",
    "    return max(texts, key=lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = load_texts_labels(df)\n",
    "maior_string = maior_text(texts)\n",
    "tam_maior_string = len(maior_string)\n",
    "print(tam_maior_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name: str, hidden_size: int, num_outputs: int):\n",
    "        super(MultiClassClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear1 = nn.Linear(self.bert.config.hidden_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_outputs)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs_bert = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs_bert.pooler_output\n",
    "        dropout = self.dropout(pooled_output)\n",
    "        logits = self.linear1(dropout)\n",
    "        logits = self.linear2(logits)\n",
    "        probs = self.softmax(logits)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: MultiClassClassifier, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  # Atualiza os pesos do modelo usando os gradientes calculados.\n",
    "        scheduler.step()  # Atualiza a taxa de aprendizado. Isso é feito após cada época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: MultiClassClassifier, data_loader: TextClassificationDataset, device: str):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():  # Desativa o cálculo de gradientes. Durante a avaliação, não precisamos calcular os gradientes, pois não estamos atualizando os pesos do modelo.\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(\n",
    "                outputs, dim=1\n",
    "            )  # Obtém as previsões do modelo encontrando o índice do valor máximo na saída do modelo.\n",
    "            predictions.extend(\n",
    "                preds.cpu().tolist()\n",
    "            )  # Adiciona as previsões  a predictions[]\n",
    "            actual_labels.extend(\n",
    "                labels.cpu().tolist()\n",
    "            )  # Adiciona os rótulos reais a actual_labels[].\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(\n",
    "        actual_labels, predictions\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tratamento_texto(text: str, lemma:bool):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"ner\"])\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(re.compile(\"<.*?>\"), \"\", text)\n",
    "    doc = nlp(text)\n",
    "    if lemma == True:\n",
    "        text = \" \".join(\n",
    "            [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "        )  # retorna o lemma\n",
    "    else:\n",
    "        text = \" \".join(\n",
    "            [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "        )  # return text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(\n",
    "    text: str, model: MultiClassClassifier, tokenizer: BertTokenizer, device: str, max_length: int\n",
    "):\n",
    "    model.eval()\n",
    "    text = predict_tratamento_texto(text, lemma=False)\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prob = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    prob_neg = prob[0, 0].item()\n",
    "    prob_pos = prob[0, 1].item()\n",
    "    print(f\"prob negativa: {prob_neg:.5f}\")\n",
    "    print(f\"prob positiva: {prob_pos:.5f}\")\n",
    "\n",
    "    if prob_neg >= 0.7 and prob_pos < 0.6:\n",
    "        return \"negative\"\n",
    "    elif prob_neg < 0.6 and prob_pos >= 0.7:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "hidden_size = 10 #Tamanho oculto, neuronios\n",
    "num_outputs = 3 # numero de neuronios saida/ categorias\n",
    "max_length = 128\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "train_dataset = TextClassificationDataset(\n",
    "    train_texts, train_labels, tokenizer, max_length\n",
    ")\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiClassClassifier(BERT_MODEL_NAME,hidden_size, num_outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "#: Isso configura o agendador de taxa de aprendizado. O agendador ajusta a taxa de aprendizado ao longo do treinamento. Neste caso, a taxa de aprendizado aumentará linearmente por um número de etapas de aquecimento e, em seguida, diminuirá linearmente.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente a Funcao fit()\n",
    "for epoch in tqdm(range(num_epochs), colour=\"green\", desc=\"Progresso: \"):\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    accuracy, report = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading Model for Inference\n",
    "\n",
    "Save:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MODEL_SAVE = \"sentiment_classifier_Bert_IMDB_Dataset_sem_lemma.pth\"\n",
    "torch.save(model.state_dict(), PATH_MODEL_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PATH_MODEL_SAVE = \"sentiment_classifier_en_49500_reviews.pth\"\n",
    "# saved_model = MultiClassClassifier(BERT_MODEL_NAME,hidden_size, num_outputs).to(device)\n",
    "# saved_model.load_state_dict(torch.load(PATH_MODEL_SAVE))\n",
    "# # saved_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capita marvel 2019 5/10\n",
    "text = \"\"\"\n",
    "    Plot\n",
    "\n",
    "Carol Danvers     becomes one of the universe's most powerful heroes when Earth is caught in the middle of a galactic war between two alien races.\n",
    "\n",
    "Cast\n",
    "\n",
    "Brie Larson, Samuel L. Jackson (Because duh), Jude \"Just consistently dreadful\" Law, Annette Bening, Djimon Hounsou, Clark Gregg and blink and you'll miss him Lee Pace who returns as Ronan but looks so different I didn't even think it was him.\n",
    "\n",
    "Verdict\n",
    "\n",
    "I watched this back when it was initially released, I watched it a second time a few days ago as the missus is wanting us to binge watch the entire MCU as she's very behind. My opinion has changed on the 2nd viewing and not in a good way, my rating has shifted from a 6/10 to 5/10.\n",
    "\n",
    "You see straight out of the gate the first thing you notice about Carol Danvers is she's not really a character you can get behind. She's not funny, she's not entertaining, she comes across as a surly teenage girl who is just upset at the slightest thing and just doesn't want to be there. This is not a character you can build a movie around, like trying to make a teenage Groot movie! It wouldn't work, but he's okay as a side character.\n",
    "\n",
    "Supporting cast are also hit and miss, Jackson and Gregg are great, but Lynch and Law just stink up every scene they're in.\n",
    "\n",
    "I'm a Marvel fan but I recognize where it's weak, this is a distinctly average film that serves as a standalone origin story and doesn't contribute much to the universe as a whole.\n",
    "\n",
    "Rants\n",
    "\n",
    "I remember when the movie came out all the controversy with Brie Larson, I just had to Google what the controversy even was as I don't remember due to not focusing on such things. Now I can't really get a definitive answer. From what I see it's a combination of people not liking her attitude and her comments on feminism. So I Googled further to see what she said, she came across arrogant in them and a smidge out of touch but none of it explained the overwhelming hate I've seen aimed at her. Then I remembered that people talk about all the different types of bigotry but misogyny rarely comes up, I remembered that it's visibly increased over the past decade and appreciated why she's been targeted. News flash, the outspoken loud brash man hating femnists you likely thing of when you hear that word make up a very small percentage. Feminism is good, if you disagree I hope you simply don't know the meaning of the word.\n",
    "\n",
    "The Good\n",
    "\n",
    "Jackson and Gregg Has a couple of decent moments Not a bad soundtrack Goose!\n",
    "\n",
    "The Bad\n",
    "\n",
    "Larson isn't great Law and Lynch are terrible Lead just comes across unlikable.\n",
    "\n",
    "Overall just a weak entry to the MC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CApita marvel 2019 6/10\n",
    "text=\"\"\"Mediocre Marvel is still pretty good.\n",
    "\n",
    "My first review in a long time! Dont know why I decided to write about this movie.\n",
    "\n",
    "I agree with most mediocre reviews I read here.\n",
    "\n",
    "The pacing was pretty good.\n",
    "\n",
    "Most of the action was good!\n",
    "\n",
    "The story was ok and had some good twists.\n",
    "\n",
    "I thought about giving this movie a 6 but after letting it sink in I decided to give it 8 out of 10\n",
    "\n",
    "It entertained me and my company from beginning to end.\n",
    "\n",
    "There were some eye rolling moments but they are easily forgiven.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "# test_text = \" very perfect very good very bad bad well, \"\n",
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "# sentiment2 = predict_sentiment(text, saved_model, tokenizer, device, max_length)\n",
    "\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")\n",
    "# print(f\"Predicted sentiment: {sentiment2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"The movie was so bad and I would not recommend it to anyone.\"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(\"Texto: \", test_text)\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"Best movie of the year. \"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(\"Worst movie of the year.\")\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"This movie is more or less very hungry\"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(test_text)\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listar tensores na GPU e CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "\n",
    "# Função para listar tensores na GPU\n",
    "def get_tensors_in_gpu():\n",
    "    print(\"\\nTensores na GPU:\")\n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj):\n",
    "            if obj.is_cuda:\n",
    "                print(type(obj), obj.size(), obj.device)\n",
    "# Listar tensores na GPU\n",
    "get_tensors_in_gpu()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Função para listar tensores na CPU\n",
    "# def get_tensors_in_cpu():\n",
    "#     print(\"\\nTensores na CPU:\")\n",
    "#     for obj in gc.get_objects():\n",
    "#         if torch.is_tensor(obj):\n",
    "#             if not obj.is_cuda:\n",
    "#                 print(type(obj), obj.size(), obj.device)\n",
    "\n",
    "# # Listar tensores na CPU\n",
    "# get_tensors_in_cpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
