{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with BERT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o ambiente virtual\n",
    "\n",
    "Digite no terminal os seguintes comandos:\n",
    "\n",
    "> python -m venv .venv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Instalando as dependências necessárias\n",
    "# ! pip install -q ipywidgets\n",
    "\n",
    "# ! pip install -q pandas\n",
    "# ! pip3 install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# ! pip install -q transformers\n",
    "#  ! pip install -q scikit-learn\n",
    "\n",
    "# # Tratamento de dados\n",
    "# ! pip install -U -q pip setuptools wheel\n",
    "# ! pip install -U -q spacy\n",
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando dependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baixar CSV DAtaset\n",
    "\n",
    "Usar o dataset obtido por meio do scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = \"D:/tcc2/guilherme/2-tratamento_dados/dataset_tratado/Scraper_Dataset_tretead_text.csv\"\n",
    "DATA_PATH= f\"D:/tcc2/guilherme/2-tratamento_dados/dataset_tratado/Scraper_Dataset_tretead_text_without_outliers.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[['review','rating']]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valores duplicados\",df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(ignore_index=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"value counts df['rating']:\")\n",
    "print(df[\"rating\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre cada categoria\n",
    "def balance_dataframe_groups(df,column, NUM_ROWS_PER_CATEGORY):\n",
    "    # Lista para armazenar os DataFrames de cada categoria(um por categoria)\n",
    "    df_list_rating = []\n",
    "    for rating, group in df.groupby(column):\n",
    "        rating_str = str(rating)  # Convertendo para string\n",
    "        num_samples = min(NUM_ROWS_PER_CATEGORY[rating_str], len(group))\n",
    "        # Selecionar aleatoriamente o número correto de linhas para cada categoria\n",
    "        sampled_rows = group.sample(n=num_samples, random_state=42)\n",
    "        # Adicionar os dados selecionados à lista\n",
    "        df_list_rating.append(sampled_rows)\n",
    "    balanced_df =pd.concat(df_list_rating)\n",
    "    return balanced_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definido para situacao onde a classe neutra vai representar os ratings [4,5,6,7]\n",
    "NUM_ROWS_PER_CATEGORY = {\n",
    "    \"1\": 2000,\n",
    "    \"2\": 2000,\n",
    "    \"3\": 2000,\n",
    "    \"4\": 1500,\n",
    "    \"5\": 1500,\n",
    "    \"6\": 1500,\n",
    "    \"7\": 1500,\n",
    "    \"8\": 2000,\n",
    "    \"9\": 2000,\n",
    "    \"10\": 2000,\n",
    "}\n",
    "# Obter dataframe balenceado\n",
    "balanced_df = balance_dataframe_groups(df, \"rating\", NUM_ROWS_PER_CATEGORY)\n",
    "\n",
    "# Verificar se as categorias estão balanceadas\n",
    "print(balanced_df[\"rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar Dataframe de teste\n",
    "\n",
    "Os dados de teste não são usados durante o treinamento do modelo e nem na validaçõa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma série com todos os índices únicos\n",
    "# df original \n",
    "df_indices = pd.Series(df.index)\n",
    "# Crie uma série com os índices que estão no balanced_df\n",
    "balanced_indices = pd.Series(balanced_df.index)\n",
    "# Selecione os índices que não estão no balanced_df\n",
    "indices_teste = df_indices[~df_indices.isin(balanced_indices)]\n",
    "# Crie um novo dataframe com os índices não presentes no balanced_df\n",
    "df_teste = df.loc[indices_teste]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_rating(rating):\n",
    "    # classe negativa[1,2,3]\n",
    "    if int(rating) <= 3:\n",
    "        return 0\n",
    "    # Classe neutra se rating in [4,5,6,7]\n",
    "    elif int(rating) <= 7:\n",
    "        return 1\n",
    "    # Classe positiva se rating in [8,9,10]\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "balanced_df[\"rating\"] = balanced_df[\"rating\"].apply(categorize_rating)\n",
    "df_teste[\"rating\"] = df_teste[\"rating\"].apply(categorize_rating)\n",
    "print(balanced_df[\"rating\"].value_counts())\n",
    "print(df_teste[\"rating\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts_labels(df):\n",
    "    texts = df[\"review\"].tolist()\n",
    "    labels = df[\"rating\"].tolist()\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maior_text(texts):\n",
    "    return max(texts, key=lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = load_texts_labels(balanced_df)\n",
    "test_texts , test_labels = load_texts_labels(df_teste)\n",
    "\n",
    "maior_string = maior_text(texts)\n",
    "tam_maior_string = len(maior_string)\n",
    "print(tam_maior_string)\n",
    "\n",
    "maior_string = maior_text(test_texts)\n",
    "tam_maior_string = len(maior_string)\n",
    "print(tam_maior_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name: str, hidden_size: int, num_outputs: int):\n",
    "        super(MultiClassClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear1 = nn.Linear(self.bert.config.hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_outputs)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs_bert = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        dropout = self.dropout(outputs_bert.pooler_output)\n",
    "        logits = self.linear1(dropout)\n",
    "        logits = self.relu(logits)\n",
    "        logits = self.linear2(logits)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_epoch(\n",
    "    model: MultiClassClassifier, data_loader, optimizer, scheduler, loss_func, device\n",
    "):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    model_prediction = []\n",
    "    actual_labels = []\n",
    "    for batch in tqdm(data_loader, colour=\"green\", desc=\"Train_epoch: \"):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        model_prediction.extend(preds.cpu().tolist())\n",
    "        actual_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    train_accuracy = accuracy_score(actual_labels, model_prediction)\n",
    "    train_loss = np.mean(losses)\n",
    "\n",
    "\n",
    "    return train_accuracy, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_epoch(\n",
    "    model: MultiClassClassifier, data_loader: TextClassificationDataset,loss_func, device: str\n",
    "):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    model_prediction = []\n",
    "    actual_labels = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, colour=\"blue\", desc=\"Validation_epoch: \"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            # Obtém as previsões do modelo encontrando o índice do valor máximo na saída do modelo.\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            # Adiciona as previsões a model_prediction[] lista de predicao de sentimento do modelo\n",
    "            model_prediction.extend(preds.cpu().tolist())\n",
    "            # Adiciona os rótulos reais a actual_labels[].\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            # Calcula a perda e adiciona à lista de perdas\n",
    "            loss = loss_func(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "    val_losses = np.mean(losses)\n",
    "    val_accuracies = accuracy_score(actual_labels, model_prediction)\n",
    "    report = classification_report(actual_labels, model_prediction)\n",
    "    return (val_accuracies, val_losses, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "hidden_size = 10  # Tamanho caamda oculto, neuronios\n",
    "num_outputs = 3  # numero de classes de saida [negativo,neutro, positivo]\n",
    "max_length = 256  # 128,256,512\n",
    "batch_size = 4  # 8, 16, 32 (tamanho do lote na iteracao, treinamento e classe)\n",
    "num_epochs = 4  # recomended in the Bert Article [2,3,4]\n",
    "learning_rate = 2e-5  # Taxa de aprendizagem (Adam): 5e-5, 3e-5, 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextClassificationDataset(\n",
    "    train_texts, train_labels, tokenizer, max_length\n",
    ")\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer, max_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiClassClassifier(BERT_MODEL_NAME,hidden_size, num_outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)# adicionado #correct_bias=False\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "loss_func = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"train_losses\": [],\n",
    "    \"train_accuracies\": [],\n",
    "    \"val_losses\": [],\n",
    "    \"val_accuracies\": [],\n",
    "    \"val_reports\": []\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "epochs_without_improvements = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs), colour=\"red\", desc=\"Epoch: \"):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    # Treinamento\n",
    "    train_accuracy, train_loss = train_model_epoch(\n",
    "        model, train_dataloader, optimizer, scheduler,loss_func, device\n",
    "    )\n",
    "    # Validation\n",
    "    val_accuracy, val_loss, report = eval_model_epoch(model, val_dataloader,loss_func, device)\n",
    "\n",
    "    history[\"train_losses\"].append(train_loss)\n",
    "    history[\"train_accuracies\"].append(train_accuracy)\n",
    "    history[\"val_losses\"].append(val_loss)\n",
    "    history[\"val_accuracies\"].append(val_accuracy)\n",
    "    history[\"val_reports\"].append(report)\n",
    "    print(f\"Train => Loss = {train_loss:.4f}, Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"Validation => Loss = {val_loss:.4f}, Accuracy = {val_accuracy:.4f}\")\n",
    "    print(report)\n",
    "    print()\n",
    "    if val_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), \"best_model_state_neutro_4_5_6_7.pth\")\n",
    "        epochs_without_improvements = 0\n",
    "        best_accuracy = val_accuracy\n",
    "    else:\n",
    "        epochs_without_improvements += 1\n",
    "\n",
    "    if epochs_without_improvements > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = history[\"train_losses\"]\n",
    "val_loss = history[\"val_losses\"]\n",
    "\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.plot(train_loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "train_acc = history[\"train_accuracies\"]\n",
    "val_acc = history[\"val_accuracies\"]\n",
    "\n",
    "# Encontrar o índice do melhor valor de acurácia de validação\n",
    "best_epoch = np.argmax(val_acc)\n",
    "best_accuracy = val_acc[best_epoch]\n",
    "plt.clf()\n",
    "plt.plot(train_acc, \"ro\", label=\"train accuracy\")\n",
    "plt.plot(val_acc, \"b\", label=\"validation accuracy\")\n",
    "# Adicionar texto para destacar o melhor valor de acurácia de validação\n",
    "plt.text(\n",
    "    best_epoch,\n",
    "    best_accuracy,\n",
    "    f\"{best_accuracy:.2f}\",\n",
    "    fontsize=12,\n",
    "    ha=\"left\",\n",
    ")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['val_reports'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading Model for Inference\n",
    "\n",
    "Save:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_MODEL_SAVE = \"sentiment_classifier_Bert_IMDB_Dataset_eith_lemma.pth\"\n",
    "# torch.save(model.state_dict(), PATH_MODEL_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PATH_MODEL_SAVE = \"sentiment_classifier_en_49500_reviews.pth\"\n",
    "# saved_model = MultiClassClassifier(BERT_MODEL_NAME,hidden_size, num_outputs).to(device)\n",
    "# saved_model.load_state_dict(torch.load(PATH_MODEL_SAVE))\n",
    "# # saved_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation in test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_accuracy, val_loss, report = eval_model_epoch(model, test_dataloader,loss_func, device)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "def predict_tratamento_texto(text: str, lemma:bool):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"ner\"])\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(re.compile(\"<.*?>\"), \"\", text)\n",
    "    doc = nlp(text)\n",
    "    if lemma == True:\n",
    "        text = \" \".join(\n",
    "            [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "        )  # retorna o lemma\n",
    "    else:\n",
    "        text = \" \".join(\n",
    "            [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "        )  # return text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_sentiment(\n",
    "    text: str,\n",
    "    model: MultiClassClassifier,\n",
    "    tokenizer: BertTokenizer,\n",
    "    device: str,\n",
    "    max_length: int,\n",
    "    lemma=False,\n",
    "):\n",
    "    model.eval()\n",
    "    text = predict_tratamento_texto(text, lemma)\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        prob = torch.nn.functional.softmax(output,dim=1)\n",
    "    prob_neg = prob[0, 0].item()\n",
    "    prob_neutra=prob[0,1].item()\n",
    "    prob_pos = prob[0, 2].item()\n",
    "    print(f\"prob negativa: {prob_neg:.5f}\")\n",
    "    print(f\"prob neutra: {prob_neutra:.5f}\")\n",
    "    print(f\"prob positiva: {prob_pos:.5f}\")\n",
    "\n",
    "    classes = [\"negativo\", \"neutro\", \"positivo\"]\n",
    "    predicted_class_index = torch.argmax(prob, dim=1).item()\n",
    "    predicted_class = classes[predicted_class_index]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challengers 1/10\n",
    "text= \"\"\"The audience was in hysterics by the end. The choices made in every aspect of this movie were shockingly bad. The abysmal and strange music, the constant shift in time, the laughable script, the nauseating camera work, and just truly one of the worst directed films I've ever seen. I would have left halfway through if I didn't have to pay for my food. But I'm glad I stayed because it got so much more hysterically bad than I even thought possible. I feel like I'm insane because the audience was screaming with laughter. I got the sense that the director thinks he's a genius, but this movie is 1% short of a feature length SNL parody.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Fall Guy 2/10\n",
    "text = \"\"\"Almost ok! But not good or great. Could had been.\n",
    "\n",
    "It was evident that the makers of this movie never saw more than couple of episodes of Fall guy the TV series it's based on. There were more reference to Miami vice tv series than the actual tv series this movie is supposedly based on. First half an hour or so of the movie was pure cringe. The dialogues were written by couple of teenagers who were probably paid in TikTok views. The rom com scenes were cringy and unwatchable.\n",
    "\n",
    "Action sequences and stunts were excellent but kept getting interrupted by really really awful cringy love story. One scene ( not a spoiler) where the action sequence keeps breaking away to a cringey Karakoram no , made us almost walk out of the movie.\n",
    "\n",
    "Some of the acting is sooo bad.\n",
    "\n",
    "If you make a movie based on the TV series Atleast watch every episode of it. We did. The tv series that made every kid want to get a pickup truck and be a stunt man. The tv series which made kids attempt dangerous stunts on their bikes.\n",
    "\n",
    "And the actual fall guy Lee majors. Makes an appearance post credit? Really. Why even bother.\n",
    "\n",
    "Was ok but a missed opportunity to make it great.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe Idea of You 3/10\n",
    "text= \"\"\"Oh dear. Absolutely no chemistry between the two main characters. The lead female Solene, apart from the absurd name is totally unrelatable or endearing. She acts like his teacher, or mother \"I'll make you a sandwich?!\" When she talks about herself he's uncomfortably interested, uncomfortable because it's not believable. The art they show in the gallery and warehouse are pretentious and boring, a lot like Solene.\n",
    "      \n",
    "I'm surprised at the positive reviews.\n",
    "\n",
    "It's mildly entertaining - a background movie for when you're building Lego for example. But I couldn't take the pairing seriously. Maybe I'm feeling the uncomfortable atmosphere that potentially could have been on set that I'm picking up on? I dunno. It could've been so much better with a different female lead.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nota 4\n",
    "text= \"\"\"I'm a big fan of Garland's earlier films (Ex Machina, Annihilation) and wanted to like this, but sadly this one was a miss. There's not really a story - no reason why the war is happening or what is at stake. The characters are extremely unrelatable and are more there just to represent concepts (the media, racism, etc) rather than have any identity of their own. The war just happens to be there in the background while the characters are taking a roadtrip through rural America, which doesn't actually show any war going on, just random series of fights which could just be regular gun violence from today. You would hardly know there's a war going on except the characters telling you there is.\n",
    "\n",
    "It's not until the last 10 minutes that you see any military operations and it lacks scale for only seemingly having about 100 troops fighting, given what's supposedly at stake. The movie should've started here and gone backwards into why the war is happening, which would've made a more interesting film in my opinion.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyone But You 5/10\n",
    "\n",
    "text = \"\"\"They really did make a whole movie just to show off Glen Powell's smoking hot body and honestly - I'm here for it!\n",
    "\n",
    "The storyline and the acting is... wait, who cares?? Glen Powell is shirtless about half the time.\n",
    "\n",
    "This is a movie about two people who fall in love only to find out that... Glen Powell's body is so hot!\n",
    "\n",
    "If you watch the trailer you already know exactly what happ... Glen Powell!!\n",
    "\n",
    "The predictability factor is super strong with this one. The cheese is sprinkled all over the movie, in every scene, there is little room left for any other ingredients because... cheese. And Glen Powell.\n",
    "\n",
    "Glen Powell\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capita marvel 2019 5/10\n",
    "text = \"\"\"Plot\n",
    "\n",
    "Carol Danvers     becomes one of the universe's most powerful heroes when Earth is caught in the middle of a galactic war between two alien races.\n",
    "\n",
    "Cast\n",
    "\n",
    "Brie Larson, Samuel L. Jackson (Because duh), Jude \"Just consistently dreadful\" Law, Annette Bening, Djimon Hounsou, Clark Gregg and blink and you'll miss him Lee Pace who returns as Ronan but looks so different I didn't even think it was him.\n",
    "\n",
    "Verdict\n",
    "\n",
    "I watched this back when it was initially released, I watched it a second time a few days ago as the missus is wanting us to binge watch the entire MCU as she's very behind. My opinion has changed on the 2nd viewing and not in a good way, my rating has shifted from a 6/10 to 5/10.\n",
    "\n",
    "You see straight out of the gate the first thing you notice about Carol Danvers is she's not really a character you can get behind. She's not funny, she's not entertaining, she comes across as a surly teenage girl who is just upset at the slightest thing and just doesn't want to be there. This is not a character you can build a movie around, like trying to make a teenage Groot movie! It wouldn't work, but he's okay as a side character.\n",
    "\n",
    "Supporting cast are also hit and miss, Jackson and Gregg are great, but Lynch and Law just stink up every scene they're in.\n",
    "\n",
    "I'm a Marvel fan but I recognize where it's weak, this is a distinctly average film that serves as a standalone origin story and doesn't contribute much to the universe as a whole.\n",
    "\n",
    "Rants\n",
    "\n",
    "I remember when the movie came out all the controversy with Brie Larson, I just had to Google what the controversy even was as I don't remember due to not focusing on such things. Now I can't really get a definitive answer. From what I see it's a combination of people not liking her attitude and her comments on feminism. So I Googled further to see what she said, she came across arrogant in them and a smidge out of touch but none of it explained the overwhelming hate I've seen aimed at her. Then I remembered that people talk about all the different types of bigotry but misogyny rarely comes up, I remembered that it's visibly increased over the past decade and appreciated why she's been targeted. News flash, the outspoken loud brash man hating femnists you likely thing of when you hear that word make up a very small percentage. Feminism is good, if you disagree I hope you simply don't know the meaning of the word.\n",
    "\n",
    "The Good\n",
    "\n",
    "Jackson and Gregg Has a couple of decent moments Not a bad soundtrack Goose!\n",
    "\n",
    "The Bad\n",
    "\n",
    "Larson isn't great Law and Lynch are terrible Lead just comes across unlikable.\n",
    "\n",
    "Overall just a weak entry to the MC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nota 5 = neutra\n",
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CApita marvel 2019 6/10\n",
    "text=\"\"\"Mediocre Marvel is still pretty good.\n",
    "\n",
    "My first review in a long time! Dont know why I decided to write about this movie.\n",
    "\n",
    "I agree with most mediocre reviews I read here.\n",
    "\n",
    "The pacing was pretty good.\n",
    "\n",
    "Most of the action was good!\n",
    "\n",
    "The story was ok and had some good twists.\n",
    "\n",
    "I thought about giving this movie a 6 but after letting it sink in I decided to give it 8 out of 10\n",
    "\n",
    "It entertained me and my company from beginning to end.\n",
    "\n",
    "There were some eye rolling moments but they are easily forgiven.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duna parte 2 6/10\n",
    "text =\"\"\"Dune Part 2 is an epic movie; slickly made, and visually stunning.\n",
    "\n",
    "But I had to explain quite a bit to the friends around me who had not read the book, especially the water of life scene and the final battle.\n",
    "\n",
    "The movie had almost a 3 hour run time, but it felt overlong because Villenue focuses too much on spectacle on very little on substance.\n",
    "\n",
    "It is a beautiful movie, but it feels like it has no soul. The emotional connection between Paul and Chani, so vital to the story, is completely lacking and unbelievable. The two main characters are good looking enough but has absolutely zero chemistry on screen.\n",
    "\n",
    "I am certain Zendaya is a fine actress in some things, but she has basically 2 facial expressions here, and the one she uses the most is a scowl directed at Paul. I found her to be the worst part of this movie.\n",
    "\n",
    "The final fight scene is short, choppy, and a mess. It felt anticlimactic and unfulfilling The Harkonens are basically reduced to bumbling villainy almost cartoonish. The ending was super abrupt, and was so different from the book that it left me wondering what the filmmakers would do if they want to do a sequel.\n",
    "\n",
    "I want to reiterate that this isn't a bad movie. Villenue is great at creating a world that looks living and breathing, but he can't give life to individual characters.\n",
    "\n",
    "It is like he can't see the trees for the forest.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duna parte 2 7/10\n",
    "\n",
    "text =\"\"\"I mean, yeah, it's very entertaining and, of course, very visually stunning. The set pieces, the cinematography, the use of visual effects and lights, the sound design and music, all, absolutely amazing and almost literally stunning!\n",
    "\n",
    "But then? I'm not really seeing much after that. As I have not read the books, this movie was a total mystery to me. There's barely any dialog--at least not any that would explain anything what's going on at all. The world and the technology etc just doesn't make much sense to me.\n",
    "\n",
    "None of the characters are particularly interesting, to be honest. They don't really have that much personality to them, and even if they did, they didn't really make me care about them all that much.\n",
    "\n",
    "I don't know, I'm a bit conflicted, it wasn't a bad movie and, as I said, it was entertaining and visually mesmerizing, but it lacked the depth that I was expecting of a world this size and this rich with lore and history. Maybe the movie makers assumed everyone has read the books? As someone to who the world is not familiar at all, it just seems rather confusing and strange. I feel like they just focused on making it as visually awesome as they can (in which they arguably succeeded), but left the story on the pages of the books.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love Lies Bleeding (2024) 8/10\n",
    "\n",
    "text=\"\"\"Love Lies Bleeding is a bigger, bolder, and more violent follow-up feature for Rose Glass. It literally puts the premise of Thelma & Louise on steroids with a very muscular approach that goes for broke in its ending which, love it or hate it, is to be commended for its audacity. Body horror, romance, and dark comedy are all blended into one distinctive vision.\n",
    "\n",
    "Kristen Stewart is amazing, awkward and off hand with one of the best dramatic pauses of recent memory. Katy O'Brian has been massively under served by her roles in the big franchises which makes this much more layered performance all the more satisfying. Together, their chemistry is instant and they communicate how badly they want each other so well.\n",
    "\n",
    "Ed Harris has played a lot of villains so its a real testament to his performance and the writing of the character that this one still stands out. His long haired, bug eating gangster makes for a consistently creepy highlight. Also, Dave Franco does a great job as a spineless abusive husband who's fate is obvious and all the more satisfying because of how he plays it.\n",
    "\n",
    "Saint Maud definitely wasn't lacking in vision but Rose Glass has really upped her craft here. From its reality manipulating opening scene to the extreme close ups of muscles in action, it's clear that the film will move between extremes as it deftly balances the violence and body horror against an affecting romance that refuses to go for the most obvious outcomes.\n",
    "\n",
    "The sound design and editing here is so visceral. Gunshots feel scary as they often come out of nowhere and the way scenes can abruptly switch between very different soundscapes keeps you on edge. Clint Mansell's score really matches the song choices for a seamless soundtrack whilst being completely distinct.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Godfather Part II (1974) 9/10\n",
    "text =\"\"\"Although the casual way it has been titled leaves it with plenty to answer for, 'Godfather II' rightly remains the only sequel ever to win an Oscar for Best Picture of the year.\n",
    "\n",
    "With Brando out of the picture the focus has shifted to Michael and much more money was obviously available to spend on the movie itself (with plush production design and cool fifties cars gliding across the screen a recurrent motif).\n",
    "\n",
    "Robert De Niro as the young Don Corleone brings a lean and hungry look to the part by then completely beyond Brando (by comparison Al Pacino looks much older).\n",
    "\n",
    "The film is far more ambitious, both technically and thematically, addressing America's changing role in the world rather than just the activities of one family.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Godfather Part II (1974) 10/10\n",
    "\n",
    "text = \"\"\"One of the all time greats. Or probably the alone greatest thing ever made in the history of cinematography. This movie is both \"prequel\" and \"sequel\" of the first godfather movie. I have never watched anything like this in my entire life. This movie has explained the life of underworld people in a great way. It also shows how vengeance eradicates happiness from your life. People don't even care about their family in greed of power. It's a masterpiece that can never be written off even after centuries. Even if you are not into these kind of movies, I will suggest to watch it for atleast once in your life or you'll be deprived of one of the greatest things to watch that have been ever made.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text,lemma= False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simples test sentiment prections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"The movie was so bad and I would not recommend it to anyone.\"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(\"Texto: \", test_text)\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"Best movie of the year. \"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(\"Worst movie of the year.\")\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"This movie is more or less,and I would not recommend it to anyone.\"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(test_text)\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
