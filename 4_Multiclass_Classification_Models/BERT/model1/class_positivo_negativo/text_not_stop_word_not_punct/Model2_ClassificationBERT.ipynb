{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## treinamento 3\n",
    "\n",
    "usando lemma sem pontuações sem stop_words\n",
    ", foram removidos os textos outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalando as dependências necessárias\n",
    "# ! pip install -q ipywidgets\n",
    "\n",
    "# #Vizualizacao e manipulacao de dados\n",
    "# ! pip install -q pandas\n",
    "# ! pip install matplotlib\n",
    "# ! pip install seaborn\n",
    "\n",
    "# ! pip3 install  torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# ! pip install  transformers\n",
    "# ! pip install  scikit-learn\n",
    "\n",
    "# Tratamento de dados\n",
    "# ! pip install -U  pip setuptools wheel\n",
    "# ! pip install -U  spacy\n",
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando dependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir nome do modelo, e diretorio para salvar o modelo posteriormente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O diretório de trabalho atual é: d:\\tcc2\\guilherme\\4_Multiclass_Classification_Models\\BERT\\model1\\class_positivo_negativo\\text_not_stop_word_not_punct\\MultiClassification.pth\n"
     ]
    }
   ],
   "source": [
    "# Obter o diretório de trabalho atual\n",
    "MODEL_NAME = \"MultiClassification\"\n",
    "PATH_ATUAL = os.getcwd()\n",
    "PATH_MODEL_SAVED = os.path.join(PATH_ATUAL, f\"{MODEL_NAME}.pth\")\n",
    "\n",
    "print(\"O diretório de trabalho atual é:\", PATH_MODEL_SAVED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baixar CSV DAtaset\n",
    "\n",
    "Usar o dataset obtido por meio do scraper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>qtd_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie take place fantasy land absolutely ridic...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentimental pathetic slow conventionally voice...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thing life understand universe begin happen so...</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie inspire brilliant Stir Crazy star Gene W...</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life understand gush cornball sentimental phon...</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40109</th>\n",
       "      <td>bloody good time Vol 1 watch Uma Thurman slice...</td>\n",
       "      <td>10</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40110</th>\n",
       "      <td>Uma Thurman return Bride time look continue st...</td>\n",
       "      <td>10</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40111</th>\n",
       "      <td>Vol 2 completely different tone feature film a...</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40112</th>\n",
       "      <td>movie great mix different genre movie martial ...</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40113</th>\n",
       "      <td>kill Bill Volume 2 direct Quentin Tarantino gr...</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  qtd_tokens\n",
       "0      movie take place fantasy land absolutely ridic...       1          34\n",
       "1      sentimental pathetic slow conventionally voice...       1          17\n",
       "2      thing life understand universe begin happen so...       1         140\n",
       "3      movie inspire brilliant Stir Crazy star Gene W...       1          84\n",
       "4      life understand gush cornball sentimental phon...       1          38\n",
       "...                                                  ...     ...         ...\n",
       "40109  bloody good time Vol 1 watch Uma Thurman slice...      10         117\n",
       "40110  Uma Thurman return Bride time look continue st...      10         156\n",
       "40111  Vol 2 completely different tone feature film a...      10          16\n",
       "40112  movie great mix different genre movie martial ...      10          60\n",
       "40113  kill Bill Volume 2 direct Quentin Tarantino gr...      10         150\n",
       "\n",
       "[40114 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"D:/tcc2/guilherme/3_Data_Processing/data/Scraper_Dataset_treated_lemma_sem_outliers.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[[\"review\", \"rating\", \"qtd_tokens\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(\n",
    "    subset=[\"review\", \"rating\"],\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>qtd_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie take place fantasy land absolutely ridic...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentimental pathetic slow conventionally voice...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thing life understand universe begin happen so...</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie inspire brilliant Stir Crazy star Gene W...</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life understand gush cornball sentimental phon...</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40109</th>\n",
       "      <td>bloody good time Vol 1 watch Uma Thurman slice...</td>\n",
       "      <td>10</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40110</th>\n",
       "      <td>Uma Thurman return Bride time look continue st...</td>\n",
       "      <td>10</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40111</th>\n",
       "      <td>Vol 2 completely different tone feature film a...</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40112</th>\n",
       "      <td>movie great mix different genre movie martial ...</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40113</th>\n",
       "      <td>kill Bill Volume 2 direct Quentin Tarantino gr...</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  qtd_tokens\n",
       "0      movie take place fantasy land absolutely ridic...       1          34\n",
       "1      sentimental pathetic slow conventionally voice...       1          17\n",
       "2      thing life understand universe begin happen so...       1         140\n",
       "3      movie inspire brilliant Stir Crazy star Gene W...       1          84\n",
       "4      life understand gush cornball sentimental phon...       1          38\n",
       "...                                                  ...     ...         ...\n",
       "40109  bloody good time Vol 1 watch Uma Thurman slice...      10         117\n",
       "40110  Uma Thurman return Bride time look continue st...      10         156\n",
       "40111  Vol 2 completely different tone feature film a...      10          16\n",
       "40112  movie great mix different genre movie martial ...      10          60\n",
       "40113  kill Bill Volume 2 direct Quentin Tarantino gr...      10         150\n",
       "\n",
       "[40114 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=[\"review\", \"rating\"], ignore_index=True)\n",
    "print(df.duplicated().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_qtd_tokens(x):\n",
    "#     return len(x.split())\n",
    "\n",
    "# df.loc[:, 'qtd_tokens'] = df['review'].apply(get_qtd_tokens)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de distribuição de palavras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotar o gráfico por quantidade de palavras\n",
    "def plot_distr_qtd_palavras(series, title):\n",
    "    mean_length = series.mean()\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(series, edgecolor=\"k\", alpha=0.7)\n",
    "    plt.axvline(mean_length, color=\"r\", linestyle=\"dashed\", linewidth=1)\n",
    "    plt.text(\n",
    "        x=mean_length * 1.1,\n",
    "        y=plt.ylim()[1] * 0.9,\n",
    "        s=f\"Média: {mean_length:.2f}\",\n",
    "        color=\"r\",\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Quantidade de palavras\")\n",
    "    plt.ylabel(\"Frequência\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "title = \"Distribuição de quantidade de palavras\"\n",
    "plot_distr_qtd_palavras(df[\"qtd_tokens\"], title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analise estatistica de quantidade de tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    40114.000000\n",
       "mean        95.761330\n",
       "std         62.873044\n",
       "min          1.000000\n",
       "25%         49.000000\n",
       "50%         81.000000\n",
       "75%        133.000000\n",
       "max        275.000000\n",
       "Name: qtd_tokens, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Analise estatistica de quantidade de tokens\")\n",
    "df[\"qtd_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value counts df['rating']:\n",
      "rating\n",
      "8     5405\n",
      "9     5294\n",
      "7     5276\n",
      "10    5163\n",
      "6     4329\n",
      "5     3527\n",
      "1     3349\n",
      "4     2801\n",
      "3     2619\n",
      "2     2351\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"value counts df['rating']:\")\n",
    "print(df[\"rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre cada categoria\n",
    "def balance_dataframe_groups(df, column, NUM_ROWS_PER_CATEGORY):\n",
    "    # Lista para armazenar os DataFrames de cada categoria(um por categoria)\n",
    "    df_list_rating = []\n",
    "    for rating, group in df.groupby(column):\n",
    "        rating_str = str(rating)  # Convertendo para string\n",
    "        num_samples = min(NUM_ROWS_PER_CATEGORY[rating_str], len(group))\n",
    "        # Selecionar aleatoriamente o número correto de linhas para cada categoria\n",
    "        sampled_rows = group.sample(n=num_samples, random_state=42)\n",
    "        # Adicionar os dados selecionados à lista\n",
    "        df_list_rating.append(sampled_rows)\n",
    "    balanced_df = pd.concat(df_list_rating)\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "8     5405\n",
      "7     5276\n",
      "6     4329\n",
      "9     4010\n",
      "10    4000\n",
      "5     3527\n",
      "1     3349\n",
      "4     2801\n",
      "3     2619\n",
      "2     2351\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Defina o número de linhas desejado para cada categoria\n",
    "NUM_ROWS_PER_CATEGORY = {\n",
    "    \"10\": 4000,\n",
    "    \"9\": 4010,\n",
    "    \"8\": 6000,\n",
    "    \"7\": 6000,\n",
    "    \"6\": 5000,\n",
    "    \"5\": 5000,\n",
    "    \"4\": 5000,\n",
    "    \"3\": 2702,\n",
    "    \"2\": 2400,\n",
    "    \"1\": 3400,\n",
    "}\n",
    "# Obter dataframe balenceado\n",
    "balanced_df = balance_dataframe_groups(df, \"rating\", NUM_ROWS_PER_CATEGORY)\n",
    "\n",
    "# Verificar se as categorias estão balanceadas\n",
    "print(balanced_df[\"rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>qtd_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20691</th>\n",
       "      <td>find incongruous people color singe dance libe...</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29862</th>\n",
       "      <td>pacing terrible 20 year old daughter want watc...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17066</th>\n",
       "      <td>love Tarantino able director follow unique sty...</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13744</th>\n",
       "      <td>go leap leep thing simple cumulative effect ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34827</th>\n",
       "      <td>open badly deceptive watch carefully patient l...</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39608</th>\n",
       "      <td>people different background fall love force st...</td>\n",
       "      <td>10</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29667</th>\n",
       "      <td>huge MMA fan know movie go good massive fan To...</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30325</th>\n",
       "      <td>amazing epic cinematic conclusion Harry Potter...</td>\n",
       "      <td>10</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39118</th>\n",
       "      <td>probably 5 3 favorite movie emotional touching...</td>\n",
       "      <td>10</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9665</th>\n",
       "      <td>summary line true way in)famous scene kick hap...</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37667 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  qtd_tokens\n",
       "20691  find incongruous people color singe dance libe...       1          63\n",
       "29862  pacing terrible 20 year old daughter want watc...       1          16\n",
       "17066  love Tarantino able director follow unique sty...       1          67\n",
       "13744  go leap leep thing simple cumulative effect ca...       1         184\n",
       "34827  open badly deceptive watch carefully patient l...       1         258\n",
       "...                                                  ...     ...         ...\n",
       "39608  people different background fall love force st...      10         106\n",
       "29667  huge MMA fan know movie go good massive fan To...      10          66\n",
       "30325  amazing epic cinematic conclusion Harry Potter...      10          84\n",
       "39118  probably 5 3 favorite movie emotional touching...      10          94\n",
       "9665   summary line true way in)famous scene kick hap...      10          96\n",
       "\n",
       "[37667 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando os dados fora do balanceamento para analise posterior, se necessário\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crie uma série com todos os índices únicos\n",
    "# # df original\n",
    "# df_indices = pd.Series(df.index)\n",
    "# # Crie uma série com os índices que estão no balanced_df\n",
    "# balanced_indices = pd.Series(balanced_df.index)\n",
    "# # Selecione os índices que não estão no balanced_df\n",
    "# indices_teste = df_indices[~df_indices.isin(balanced_indices)]\n",
    "# # Crie um novo dataframe com os índices não presentes no balanced_df\n",
    "# df_fora_balanceamento = df.loc[indices_teste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fora_balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Para Classe Positivo[7,8,9,10] e Negativo [...]\n",
    "def categorize_rating(rating):\n",
    "    if int(rating) <= 6:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "0    18976\n",
      "1    18691\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balanced_df[\"rating\"] = balanced_df[\"rating\"].apply(categorize_rating)\n",
    "print(balanced_df[\"rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executar a celular abaixo somente se for necessário balancear novamente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Defina o número de linhas desejado para cada categoria\n",
    "NUM_ROWS_PER_CATEGORY = {\n",
    "    \"1\": 5000,\n",
    "    \"0\": 5000,\n",
    "}\n",
    "\n",
    "# Obter dataframe balenceado\n",
    "balanced_df = balance_dataframe_groups(balanced_df, \"rating\", NUM_ROWS_PER_CATEGORY)\n",
    "\n",
    "# Verificar se as categorias estão balanceadas\n",
    "print(balanced_df[\"rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>qtd_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>classic need movie find ok find slow drag ab t...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29683</th>\n",
       "      <td>ok totally miss point idiot review talk heartf...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12293</th>\n",
       "      <td>bad WWII movie see see cinema error list nomen...</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>1 hour half movie boyfriend tell feel like tak...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35836</th>\n",
       "      <td>watch notice good picture winner cover think w...</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>epic historical drama set 1586 Japan feudalism...</td>\n",
       "      <td>1</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33934</th>\n",
       "      <td>rich tenser atmospheric way well film Clouzot ...</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>City God adrenaline jolt film manage find bala...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24064</th>\n",
       "      <td>let explain 1990 Goodfellas story Henry Hill l...</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18370</th>\n",
       "      <td>film critic Roger Ebert say film clearly hatre...</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  qtd_tokens\n",
       "9574   classic need movie find ok find slow drag ab t...       0          24\n",
       "29683  ok totally miss point idiot review talk heartf...       0          40\n",
       "12293  bad WWII movie see see cinema error list nomen...       0          76\n",
       "4559   1 hour half movie boyfriend tell feel like tak...       0          51\n",
       "35836  watch notice good picture winner cover think w...       0          59\n",
       "...                                                  ...     ...         ...\n",
       "4281   epic historical drama set 1586 Japan feudalism...       1         254\n",
       "33934  rich tenser atmospheric way well film Clouzot ...       1         189\n",
       "5068   City God adrenaline jolt film manage find bala...       1          88\n",
       "24064  let explain 1990 Goodfellas story Henry Hill l...       1         203\n",
       "18370  film critic Roger Ebert say film clearly hatre...       1          98\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tonar o df balanceado como padrão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>qtd_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>classic need movie find ok find slow drag ab t...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29683</th>\n",
       "      <td>ok totally miss point idiot review talk heartf...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12293</th>\n",
       "      <td>bad WWII movie see see cinema error list nomen...</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>1 hour half movie boyfriend tell feel like tak...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35836</th>\n",
       "      <td>watch notice good picture winner cover think w...</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>epic historical drama set 1586 Japan feudalism...</td>\n",
       "      <td>1</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33934</th>\n",
       "      <td>rich tenser atmospheric way well film Clouzot ...</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>City God adrenaline jolt film manage find bala...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24064</th>\n",
       "      <td>let explain 1990 Goodfellas story Henry Hill l...</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18370</th>\n",
       "      <td>film critic Roger Ebert say film clearly hatre...</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  qtd_tokens\n",
       "9574   classic need movie find ok find slow drag ab t...       0          24\n",
       "29683  ok totally miss point idiot review talk heartf...       0          40\n",
       "12293  bad WWII movie see see cinema error list nomen...       0          76\n",
       "4559   1 hour half movie boyfriend tell feel like tak...       0          51\n",
       "35836  watch notice good picture winner cover think w...       0          59\n",
       "...                                                  ...     ...         ...\n",
       "4281   epic historical drama set 1586 Japan feudalism...       1         254\n",
       "33934  rich tenser atmospheric way well film Clouzot ...       1         189\n",
       "5068   City God adrenaline jolt film manage find bala...       1          88\n",
       "24064  let explain 1990 Goodfellas story Henry Hill l...       1         203\n",
       "18370  film critic Roger Ebert say film clearly hatre...       1          98\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>qtd_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>95.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500025</td>\n",
       "      <td>62.693996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating    qtd_tokens\n",
       "count  10000.000000  10000.000000\n",
       "mean       0.500000     95.143800\n",
       "std        0.500025     62.693996\n",
       "min        0.000000      2.000000\n",
       "25%        0.000000     49.000000\n",
       "50%        0.500000     80.000000\n",
       "75%        1.000000    133.000000\n",
       "max        1.000000    275.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts_labels(df):\n",
    "    texts = df[\"review\"].tolist()\n",
    "    labels = df[\"rating\"].tolist()\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = load_texts_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name: str, hidden_size: int, num_outputs: int):\n",
    "        super(MultiClassClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.linear1 = nn.Linear(self.bert.config.hidden_size, num_outputs)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs_bert = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs_bert.pooler_output\n",
    "\n",
    "        logits = self.linear1(pooled_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_epoch(\n",
    "    model: MultiClassClassifier, data_loader, optimizer, scheduler, loss_func, device\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    model_prediction = []\n",
    "    actual_labels = []\n",
    "\n",
    "    for batch in tqdm(data_loader, colour=\"green\", desc=\"Train_epoch: \"):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        model_prediction.extend(preds.cpu().tolist())\n",
    "        actual_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    train_accuracy = accuracy_score(actual_labels, model_prediction)\n",
    "    train_loss = np.mean(losses)\n",
    "\n",
    "    return train_accuracy, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_epoch(\n",
    "    model: MultiClassClassifier,\n",
    "    data_loader: TextClassificationDataset,\n",
    "    loss_func,\n",
    "    device: str,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    model_prediction = []\n",
    "    real_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, colour=\"blue\", desc=\"Validation_epoch: \"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            model_prediction.extend(preds.cpu().tolist())\n",
    "            real_labels.extend(labels.cpu().tolist())\n",
    "            loss = loss_func(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    val_losses = np.mean(losses)\n",
    "    val_accuracies = accuracy_score(real_labels, model_prediction)\n",
    "    report = classification_report(real_labels, model_prediction, output_dict=False)\n",
    "\n",
    "    return (val_accuracies, val_losses, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "hidden_size = 10  # Tamanho oculto, neuronios\n",
    "num_outputs = 2  # numero de classes de saida [negativo,positivo]\n",
    "max_length = 256  # 128\n",
    "batch_size = 8  # 16, 32\n",
    "num_epochs = 10  # recomended in the Bert Article [2,3,4]\n",
    "learning_rate = 10e-5  # Taxa de aprendizagem (Adam): 5e-5, 3e-5, 2e-5\n",
    "weight_decay = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    texts, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextClassificationDataset(\n",
    "    train_texts, train_labels, tokenizer, max_length\n",
    ")\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# # Create prediction_dataset\n",
    "test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer, max_length)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiClassClassifier(\n",
    "    BERT_MODEL_NAME, hidden_size=hidden_size, num_outputs=num_outputs\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "#: Isso configura o agendador de taxa de aprendizado.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=2, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train_epoch:   4%|\u001b[32m▎         \u001b[0m| 31/875 [03:34<1:37:22,  6.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:26\u001b[0m\n",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m, in \u001b[0;36mtrain_model_epoch\u001b[1;34m(model, data_loader, optimizer, scheduler, loss_func, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, labels)\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 8\u001b[0m, in \u001b[0;36mMultiClassClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m----> 8\u001b[0m     outputs_bert \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs_bert\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[0;32m     11\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(pooled_output)\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1137\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1137\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1149\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1150\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:690\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    679\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    680\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    681\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m         output_attentions,\n\u001b[0;32m    688\u001b[0m     )\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 690\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:622\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    619\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    620\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 622\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:635\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    634\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 635\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:547\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 547\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    548\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    549\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\tcc2\\guilherme\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "# Definindo a frequência e a duração do bip\n",
    "frequency = 400  # Define a frequência para 2500 Hertz\n",
    "duration = 500  # Define a duração para 1000 ms == 1 segundo\n",
    "\n",
    "\n",
    "\n",
    "history_epoch = {\n",
    "    \"train_losses\": [],\n",
    "    \"train_accuracies\": [],\n",
    "    \"val_losses\": [],\n",
    "    \"val_accuracies\": [],\n",
    "    \"val_reports\": [],\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "epochs_without_improvements = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Treinamento\n",
    "    train_accuracy, train_loss = train_model_epoch(\n",
    "        model, train_dataloader, optimizer, scheduler, loss_func, device\n",
    "    )\n",
    "    # Validation\n",
    "    val_accuracy, val_loss, report = eval_model_epoch(\n",
    "        model, val_dataloader, loss_func, device\n",
    "    )\n",
    "\n",
    "    history_epoch[\"train_losses\"].append(train_loss)\n",
    "    history_epoch[\"train_accuracies\"].append(train_accuracy)\n",
    "    history_epoch[\"val_losses\"].append(val_loss)\n",
    "    history_epoch[\"val_accuracies\"].append(val_accuracy)\n",
    "    history_epoch[\"val_reports\"].append(report)\n",
    "\n",
    "    print(f\"Train => Loss = {train_loss:.4f}, Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"Validation => Loss = {val_loss:.4f}, Accuracy = {val_accuracy:.4f}\")\n",
    "    print(report)\n",
    "    print()\n",
    "    if val_accuracy > best_accuracy:\n",
    "        try:\n",
    "            torch.save(model.state_dict(), PATH_MODEL_SAVED)\n",
    "            print(\"Modelo salvo com sucesso!\")\n",
    "        except Exception as e:\n",
    "            print(\"Ocorreu um erro ao tentar salvar o modelo.\")\n",
    "            print(\"Detalhes do erro:\", str(e))\n",
    "        epochs_without_improvements = 0\n",
    "        best_accuracy = val_accuracy\n",
    "    else:\n",
    "        epochs_without_improvements += 1\n",
    "\n",
    "    if epochs_without_improvements > 4:\n",
    "        break\n",
    "     # Seu código aqui\n",
    "    time.sleep(1)  # Simulando um tempo de processamento\n",
    "    winsound.Beep(frequency, duration) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_accuracies: \", history_epoch[\"train_accuracies\"])\n",
    "print(\"val_accuracies: \", history_epoch[\"val_accuracies\"])\n",
    "print(history_epoch[\"val_reports\"][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Graph losses and acurracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_loss = history_epoch[\"train_losses\"]\n",
    "val_loss = history_epoch[\"val_losses\"]\n",
    "\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "def plot_loss_fun_graph(train_loss, val_loss):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss, \"r\", linestyle='--', label=\"Training loss\")\n",
    "    plt.scatter(range(len(train_loss)), train_loss, color='red')  # Adiciona pontos vermelhos para perda de treinamento\n",
    "    plt.plot(val_loss, \"b\", linestyle='-', label=\"Validation loss\")\n",
    "    plt.scatter(range(len(val_loss)), val_loss, color='blue')  # Adiciona pontos azuis para perda de validação\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\", fontsize=14)\n",
    "    plt.xlabel(\"Epochs\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_loss_fun_graph(train_loss, val_loss)\n",
    "\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "train_acc = history_epoch[\"train_accuracies\"]\n",
    "val_acc = history_epoch[\"val_accuracies\"]\n",
    "\n",
    "\n",
    "# Encontrar o índice do melhor valor de acurácia de validação\n",
    "def plot_accurary_graph(train_acc, val_acc):\n",
    "    best_epoch = np.argmax(val_acc)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_acc, \"r\", linestyle='--', label=\"Training accuracy\")\n",
    "    plt.scatter(range(len(train_acc)), train_acc, color='red')  # Adiciona pontos vermelhos para acurácia de treinamento\n",
    "    plt.plot(val_acc, \"b\", linestyle='-', label=\"validation accuracy\")\n",
    "    plt.scatter(range(len(val_acc)), val_acc, color='blue')  # Adiciona pontos azuis para acurácia de validação\n",
    "    plt.title(\"Training and Validation Accuracy Over Epochs\", fontsize=14)\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_accurary_graph(train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading Model for Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_MODEL_SAVE = \"sentiment_classifier_Bert_IMDB_Dataset_eith_lemma.pth\"\n",
    "# torch.save(model.state_dict(), PATH_MODEL_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PATH_MODEL_SAVE = \"sentiment_classifier_en_49500_reviews.pth\"\n",
    "# saved_model = MultiClassClassifier(BERT_MODEL_NAME,hidden_size, num_outputs).to(device)\n",
    "# saved_model.load_state_dict(torch.load(PATH_MODEL_SAVE))\n",
    "# # saved_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation in test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predicitons in test_texts and test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "\n",
    "    # corresponde ao indice(classe) com maior probabilidade na saída do modelo\n",
    "    predictions = []\n",
    "    # corresponde ao indice real(classe verdadeira)\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            m_output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = F.softmax(m_output, dim=1)\n",
    "\n",
    "            _, max_index = torch.max(probs, dim=1)\n",
    "\n",
    "            predictions.extend(max_index)\n",
    "            real_values.extend(labels)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "\n",
    "    return predictions, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CArregando com o modelo final atualizado\n",
    "test_predictions, test_real_values = get_predictions(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_names = [\"negativo\", \"positivo\"]\n",
    "test_accuracies = accuracy_score(test_predictions, test_real_values)\n",
    "\n",
    "test_report = classification_report(\n",
    "    test_predictions,\n",
    "    test_real_values,\n",
    "    target_names=classes_names,\n",
    "    output_dict=True,\n",
    "    digits=6,\n",
    ")\n",
    "print(f\"A precisão foi: {test_accuracies*100:.4f}\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_report).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(test_predictions, test_real_values)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=classes_names).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def show_confusion_matrix(confusion_matrix):\n",
    "    hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha=\"right\")\n",
    "    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"True sentiment\")\n",
    "    plt.xlabel(\"Predicted sentiment\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_predictions, test_real_values)\n",
    "df_cm = pd.DataFrame(cm, index=classes_names, columns=classes_names)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "\n",
    "def predict_tratamento_texto(text: str, lemma: bool):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"ner\"])\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    # remover html\n",
    "    # text = re.sub(re.compile(\"<.*?>\"), \"\", text)\n",
    "    doc = nlp(text)\n",
    "    if lemma == True:\n",
    "        text = \" \".join(\n",
    "            [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "        )  # retorna o lemma\n",
    "    else:\n",
    "        text = \" \".join(\n",
    "            [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "        )  # return text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(\n",
    "    text: str,\n",
    "    model: MultiClassClassifier,\n",
    "    tokenizer: BertTokenizer,\n",
    "    device: str,\n",
    "    max_length: int,\n",
    "    lemma=False,\n",
    "):\n",
    "    model.eval()\n",
    "    text = predict_tratamento_texto(text, lemma)\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        prob = F.softmax(output, dim=1)\n",
    "    prob_neg = prob[0, 0].item()\n",
    "    prob_pos = prob[0, 1].item()\n",
    "    print(f\"prob negativa: {prob_neg:.5f}\")\n",
    "    print(f\"prob positiva: {prob_pos:.5f}\")\n",
    "\n",
    "    classes = [\"negativo\", \"positivo\"]\n",
    "    predicted_class_index = torch.argmax(prob, dim=1).item()\n",
    "    predicted_class = classes[predicted_class_index]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challengers 1/10\n",
    "text = \"\"\"The audience was in hysterics by the end. The choices made in every aspect of this movie were shockingly bad. The abysmal and strange music, the constant shift in time, the laughable script, the nauseating camera work, and just truly one of the worst directed films I've ever seen. I would have left halfway through if I didn't have to pay for my food. But I'm glad I stayed because it got so much more hysterically bad than I even thought possible. I feel like I'm insane because the audience was screaming with laughter. I got the sense that the director thinks he's a genius, but this movie is 1% short of a feature length SNL parody.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Fall Guy 2/10\n",
    "text = \"\"\"Almost ok! But not good or great. Could had been.  It was evident that the makers of this movie never saw more than couple of episodes of Fall guy the TV series it's based on. There were more reference to Miami vice tv series than the actual tv series this movie is supposedly based on. First half an hour or so of the movie was pure cringe. The dialogues were written by couple of teenagers who were probably paid in TikTok views. The rom com scenes were cringy and unwatchable.  Action sequences and stunts were excellent but kept getting interrupted by really really awful cringy love story. One scene ( not a spoiler) where the action sequence keeps breaking away to a cringey Karakoram no , made us almost walk out of the movie.  Some of the acting is sooo bad.  If you make a movie based on the TV series Atleast watch every episode of it. We did. The tv series that made every kid want to get a pickup truck and be a stunt man. The tv series which made kids attempt dangerous stunts on their bikes.  And the actual fall guy Lee majors. Makes an appearance post credit? Really. Why even bother.  Was ok but a missed opportunity to make it great.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe Idea of You 3/10\n",
    "text = \"\"\"Oh dear. Absolutely no chemistry between the two main characters. The lead female Solene, apart from the absurd name is totally unrelatable or endearing. She acts like his teacher, or mother \"I'll make you a sandwich?!\" When she talks about herself he's uncomfortably interested, uncomfortable because it's not believable. The art they show in the gallery and warehouse are pretentious and boring, a lot like Solene. I'm surprised at the positive reviews.  It's mildly entertaining - a background movie for when you're building Lego for example. But I couldn't take the pairing seriously. Maybe I'm feeling the uncomfortable atmosphere that potentially could have been on set that I'm picking up on? I dunno. It could've been so much better with a different female lead.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nota 4\n",
    "text = \"\"\"I'm a big fan of Garland's earlier films (Ex Machina, Annihilation) and wanted to like this, but sadly this one was a miss. There's not really a story - no reason why the war is happening or what is at stake. The characters are extremely unrelatable and are more there just to represent concepts (the media, racism, etc) rather than have any identity of their own. The war just happens to be there in the background while the characters are taking a roadtrip through rural America, which doesn't actually show any war going on, just random series of fights which could just be regular gun violence from today. You would hardly know there's a war going on except the characters telling you there is.  It's not until the last 10 minutes that you see any military operations and it lacks scale for only seemingly having about 100 troops fighting, given what's supposedly at stake. The movie should've started here and gone backwards into why the war is happening, which would've made a more interesting film in my opinion.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyone But You 5/10\n",
    "\n",
    "text = \"\"\"They really did make a whole movie just to show off Glen Powell's smoking hot body and honestly - I'm here for it! The storyline and the acting is... wait, who cares?? Glen Powell is shirtless about half the time. This is a movie about two people who fall in love only to find out that... Glen Powell's body is so hot! If you watch the trailer you already know exactly what happ... Glen Powell!! The predictability factor is super strong with this one. The cheese is sprinkled all over the movie, in every scene, there is little room left for any other ingredients because... cheese. And Glen Powell.  Glen Powell\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capita marvel 2019 5/10\n",
    "text = \"\"\"Plot  Carol Danvers     becomes one of the universe's most powerful heroes when Earth is caught in the middle of a galactic war between two alien races.  Cast  Brie Larson, Samuel L. Jackson (Because duh), Jude \"Just consistently dreadful\" Law, Annette Bening, Djimon Hounsou, Clark Gregg and blink and you'll miss him Lee Pace who returns as Ronan but looks so different I didn't even think it was him.  Verdict  I watched this back when it was initially released, I watched it a second time a few days ago as the missus is wanting us to binge watch the entire MCU as she's very behind. My opinion has changed on the 2nd viewing and not in a good way, my rating has shifted from a 6/10 to 5/10.  You see straight out of the gate the first thing you notice about Carol Danvers is she's not really a character you can get behind. She's not funny, she's not entertaining, she comes across as a surly teenage girl who is just upset at the slightest thing and just doesn't want to be there. This is not a character you can build a movie around, like trying to make a teenage Groot movie! It wouldn't work, but he's okay as a side character.  Supporting cast are also hit and miss, Jackson and Gregg are great, but Lynch and Law just stink up every scene they're in.  I'm a Marvel fan but I recognize where it's weak, this is a distinctly average film that serves as a standalone origin story and doesn't contribute much to the universe as a whole.  Rants  I remember when the movie came out all the controversy with Brie Larson, I just had to Google what the controversy even was as I don't remember due to not focusing on such things. Now I can't really get a definitive answer. From what I see it's a combination of people not liking her attitude and her comments on feminism. So I Googled further to see what she said, she came across arrogant in them and a smidge out of touch but none of it explained the overwhelming hate I've seen aimed at her. Then I remembered that people talk about all the different types of bigotry but misogyny rarely comes up, I remembered that it's visibly increased over the past decade and appreciated why she's been targeted. News flash, the outspoken loud brash man hating femnists you likely thing of when you hear that word make up a very small percentage. Feminism is good, if you disagree I hope you simply don't know the meaning of the word.  The Good  Jackson and Gregg Has a couple of decent moments Not a bad soundtrack Goose!  The Bad  Larson isn't great Law and Lynch are terrible Lead just comes across unlikable.  Overall just a weak entry to the MC \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nota 5 = neutra\n",
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CApita marvel 2019 6/10\n",
    "text = \"\"\"Mediocre Marvel is still pretty good. My first review in a long time! Dont know why I decided to write about this movie. I agree with most mediocre reviews I read here. The pacing was pretty good. Most of the action was good! The story was ok and had some good twists. I thought about giving this movie a 6 but after letting it sink in I decided to give it 8 out of 10 It entertained me and my company from beginning to end. There were some eye rolling moments but they are easily forgiven.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duna parte 2 6/10\n",
    "text = \"\"\"Dune Part 2 is an epic movie; slickly made, and visually stunning.  But I had to explain quite a bit to the friends around me who had not read the book, especially the water of life scene and the final battle.  The movie had almost a 3 hour run time, but it felt overlong because Villenue focuses too much on spectacle on very little on substance.  It is a beautiful movie, but it feels like it has no soul. The emotional connection between Paul and Chani, so vital to the story, is completely lacking and unbelievable. The two main characters are good looking enough but has absolutely zero chemistry on screen.  I am certain Zendaya is a fine actress in some things, but she has basically 2 facial expressions here, and the one she uses the most is a scowl directed at Paul. I found her to be the worst part of this movie.  The final fight scene is short, choppy, and a mess. It felt anticlimactic and unfulfilling The Harkonens are basically reduced to bumbling villainy almost cartoonish. The ending was super abrupt, and was so different from the book that it left me wondering what the filmmakers would do if they want to do a sequel.  I want to reiterate that this isn't a bad movie. Villenue is great at creating a world that looks living and breathing, but he can't give life to individual characters.  It is like he can't see the trees for the forest.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duna parte 2 7/10\n",
    "text = \"\"\"I mean, yeah, it's very entertaining and, of course, very visually stunning. The set pieces, the cinematography, the use of visual effects and lights, the sound design and music, all, absolutely amazing and almost literally stunning!  But then? I'm not really seeing much after that. As I have not read the books, this movie was a total mystery to me. There's barely any dialog--at least not any that would explain anything what's going on at all. The world and the technology etc just doesn't make much sense to me.  None of the characters are particularly interesting, to be honest. They don't really have that much personality to them, and even if they did, they didn't really make me care about them all that much.  I don't know, I'm a bit conflicted, it wasn't a bad movie and, as I said, it was entertaining and visually mesmerizing, but it lacked the depth that I was expecting of a world this size and this rich with lore and history_epoch. Maybe the movie makers assumed everyone has read the books? As someone to who the world is not familiar at all, it just seems rather confusing and strange. I feel like they just focused on making it as visually awesome as they can (in which they arguably succeeded), but left the story on the pages of the books.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love Lies Bleeding (2024) 8/10\n",
    "text = \"\"\"Love Lies Bleeding is a bigger, bolder, and more violent follow-up feature for Rose Glass. It literally puts the premise of Thelma & Louise on steroids with a very muscular approach that goes for broke in its ending which, love it or hate it, is to be commended for its audacity. Body horror, romance, and dark comedy are all blended into one distinctive vision.  Kristen Stewart is amazing, awkward and off hand with one of the best dramatic pauses of recent memory. Katy O'Brian has been massively under served by her roles in the big franchises which makes this much more layered performance all the more satisfying. Together, their chemistry is instant and they communicate how badly they want each other so well.  Ed Harris has played a lot of villains so its a real testament to his performance and the writing of the character that this one still stands out. His long haired, bug eating gangster makes for a consistently creepy highlight. Also, Dave Franco does a great job as a spineless abusive husband who's fate is obvious and all the more satisfying because of how he plays it.  Saint Maud definitely wasn't lacking in vision but Rose Glass has really upped her craft here. From its reality manipulating opening scene to the extreme close ups of muscles in action, it's clear that the film will move between extremes as it deftly balances the violence and body horror against an affecting romance that refuses to go for the most obvious outcomes.  The sound design and editing here is so visceral. Gunshots feel scary as they often come out of nowhere and the way scenes can abruptly switch between very different soundscapes keeps you on edge. Clint Mansell's score really matches the song choices for a seamless soundtrack whilst being completely distinct.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Godfather Part II (1974) 9/10\n",
    "text = \"\"\"Although the casual way it has been titled leaves it with plenty to answer for, 'Godfather II' rightly remains the only sequel ever to win an Oscar for Best Picture of the year.  With Brando out of the picture the focus has shifted to Michael and much more money was obviously available to spend on the movie itself (with plush production design and cool fifties cars gliding across the screen a recurrent motif).  Robert De Niro as the young Don Corleone brings a lean and hungry look to the part by then completely beyond Brando (by comparison Al Pacino looks much older).  The film is far more ambitious, both technically and thematically, addressing America's changing role in the world rather than just the activities of one family.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Godfather Part II (1974) 10/10\n",
    "\n",
    "text = \"\"\"One of the all time greats. Or probably the alone greatest thing ever made in the history_epoch of cinematography. This movie is both \"prequel\" and \"sequel\" of the first godfather movie. I have never watched anything like this in my entire life. This movie has explained the life of underworld people in a great way. It also shows how vengeance eradicates happiness from your life. People don't even care about their family in greed of power. It's a masterpiece that can never be written off even after centuries. Even if you are not into these kind of movies, I will suggest to watch it for atleast once in your life or you'll be deprived of one of the greatest things to watch that have been ever made.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment(text, model, tokenizer, device, max_length)\n",
    "print(predict_tratamento_texto(text, lemma=False))\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simples test sentiment prections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"The movie was so bad and I would not recommend it to anyone.\"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(\"Texto: \", test_text)\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = \"Best movie of the year. \"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(\"Worst movie of the year.\")\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentiment prediction\n",
    "test_text = (\n",
    "    \"This movie is more or less,and I would not recommend it to anyone, but i busy.\"\n",
    ")\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(test_text)\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
