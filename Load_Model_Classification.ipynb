{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name: str, num_classes: int):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear1 = nn.Linear(self.bert.config.hidden_size, 10)\n",
    "        self.linear2 = nn.Linear(10, 3)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Passando os dados de entrada pelo modelo BERT\n",
    "        outputs_bert = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Obtendo a representação do pooler output, que captura o contexto da sequência de entrada\n",
    "        pooled_output = outputs_bert.pooler_output\n",
    "        # Aplicando dropout à representação do pooler output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.linear1(x)\n",
    "        logits_out = self.linear2(logits)\n",
    "        # saida = self.softmax(logits_out)\n",
    "        return logits_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: BertModel, data_loader, optimizer, scheduler, device):\n",
    "    # Define modelo no modo de treinamento .  Isso é necessário porque certas camadas como Dropout e BatchNorm se comportam de maneira diferente durante o treinamento.\n",
    "    model.train()\n",
    "\n",
    "#batch: dict ->{'input_ids': tensor([[...]]),\n",
    "# 'attention_mask':tensor([[...]]),\n",
    "# 'label':tensor([[...]]}\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  # Atualiza os pesos do modelo usando os gradientes calculados.\n",
    "        scheduler.step()  # Atualiza a taxa de aprendizado. Isso é feito após cada época\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: BertModel, data_loader: TextClassificationDataset, device: str):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():  # Desativa o cálculo de gradientes. Durante a avaliação, não precisamos calcular os gradientes, pois não estamos atualizando os pesos do modelo.\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(\n",
    "                outputs, dim=1\n",
    "            )  # Obtém as previsões do modelo encontrando o índice do valor máximo na saída do modelo.\n",
    "            predictions.extend(\n",
    "                preds.cpu().tolist()\n",
    "            )  # Adiciona as previsões  a predictions[]\n",
    "            actual_labels.extend(\n",
    "                labels.cpu().tolist()\n",
    "            )  # Adiciona os rótulos reais a actual_labels[].\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(\n",
    "        actual_labels, predictions\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_tratamento_texto(text: str):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"ner\"])\n",
    "    doc = nlp(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\" +\", \" \", text).strip()\n",
    "    text = re.sub(re.compile(\"<.*?>\"), \"\", text)\n",
    "    text = \" \".join(\n",
    "        [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(\n",
    "    text: str, model: BertModel, tokenizer: BertTokenizer, device: str, max_length: int\n",
    "):\n",
    "    r\"\"\"é usada após a fase de ajuste(fit) do modelo,\n",
    "    quando você deseja fazer previsões/inferências em novos textos que o modelo não viu durante o treinamento.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    text = predict_tratamento_texto(text)\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #OUTPUTS POSSUI 3 SAIDAS\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    print(\"preds: \", preds)\n",
    "    print(outputs)\n",
    "\n",
    "    print(preds.item())\n",
    "\n",
    "    return \"positive\" if preds.item() == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(\n",
    "    text: str, model: BertModel, tokenizer: BertTokenizer, device: str, max_length: int\n",
    "):\n",
    "    model.eval()\n",
    "    text = predict_tratamento_texto(text)\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    if preds.item() == 1:\n",
    "        return \"positive\"\n",
    "    elif preds.item() == 0:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "num_classes = 10  # numero de neuronios\n",
    "max_length = 128\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_MODEL_SAVE = \"sentiment_classifier_en_49500_reviews.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)\n",
    "model.load_state_dict(torch.load(PATH_MODEL_SAVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a Marvel fan. I go see all the movies, then buy the blu-rays. I have character statues, posters and have read the comics including Captain Marvel. There is a reason people become fans of certain things, and those things done well over time generate more fans until it becomes a \"Juggernaut\" like the MCU has. I fear that it's not unstoppable however, as the sub-par Captain Marvel has painfully illustrated. The movie is a pastiche of poorly written scenes with a bit of uninspired action sprinkled here and there with barely any plot at all. Carol Danvers has no character development whatsoever, no adversity to overcome besides amnesia and no villain to fight. I know there are people saying they like this movie, but I feel like they either aren't being honest or they like it for personal reasons that are not present in the movie. Objectively speaking, in terms of the technical aspects of storytelling, Captain Marvel just isn't effective. Subjectively, I was bored the entire time and the nostalgia parts made me feel as though JJ Abrams was poking me in the ribs asking me if I 'member the 90's. Yes. Yes I do. And for the record, people are criticizing this movie because it was bad, not because they \"haaaate the wooomans!\" Dismissing legitimate criticisms using this tactic will not produce better films, which is the only thing most people want. The problem is that they built the movie around the idea of \"strong woman\" and promoted it as an identity film, so when the movie ends up being bad some people rush to defend it because they don't want the IDEA to fail. The movie itself is secondary - just a vehicle to slap their bumper stickers on, which is a real shame because this could have been a great addition to the MCU. I hope they learn something from this, but from what I've heard it appears that Marvel actually plans to escalate the identity politics in the next phase which would be an absolute disaster for them. When pointing to the box office as a defense for how \"good\" Captain Marvel was, just remember that tons of paying customers didn't like it at all.\n",
      "Predicted sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# Capitã Marvel (2019) nota 3/10\n",
    "test_text = f'I am a Marvel fan. I go see all the movies, then buy the blu-rays. I have character statues, posters and have read the comics including Captain Marvel. There is a reason people become fans of certain things, and those things done well over time generate more fans until it becomes a \"Juggernaut\" like the MCU has. I fear that it\\'s not unstoppable however, as the sub-par Captain Marvel has painfully illustrated. The movie is a pastiche of poorly written scenes with a bit of uninspired action sprinkled here and there with barely any plot at all. Carol Danvers has no character development whatsoever, no adversity to overcome besides amnesia and no villain to fight. I know there are people saying they like this movie, but I feel like they either aren\\'t being honest or they like it for personal reasons that are not present in the movie. Objectively speaking, in terms of the technical aspects of storytelling, Captain Marvel just isn\\'t effective. Subjectively, I was bored the entire time and the nostalgia parts made me feel as though JJ Abrams was poking me in the ribs asking me if I \\'member the 90\\'s. Yes. Yes I do. And for the record, people are criticizing this movie because it was bad, not because they \"haaaate the wooomans!\" Dismissing legitimate criticisms using this tactic will not produce better films, which is the only thing most people want. The problem is that they built the movie around the idea of \"strong woman\" and promoted it as an identity film, so when the movie ends up being bad some people rush to defend it because they don\\'t want the IDEA to fail. The movie itself is secondary - just a vehicle to slap their bumper stickers on, which is a real shame because this could have been a great addition to the MCU. I hope they learn something from this, but from what I\\'ve heard it appears that Marvel actually plans to escalate the identity politics in the next phase which would be an absolute disaster for them. When pointing to the box office as a defense for how \"good\" Captain Marvel was, just remember that tons of paying customers didn\\'t like it at all.'\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(test_text)\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved every moment of this film. We speak so much about representation and here it is in a beautifully wrapped box. Where was this hitter when I was growing up in southwest Virginia? Not in my library I assure you. And yes, I know this isn't the real origin story. But I needed this movie. I am 41 years old. It shouldn't have taken this long.\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Capitã Marvel (2019) nota 10/10\n",
    "test_text = \"\"\"I loved every moment of this film. We speak so much about representation and here it is in a beautifully wrapped box. Where was this hitter when I was growing up in southwest Virginia? Not in my library I assure you. And yes, I know this isn't the real origin story. But I needed this movie. I am 41 years old. It shouldn't have taken this long.\"\"\"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device, max_length)\n",
    "print(test_text)\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-tcc",
   "language": "python",
   "name": ".venv-tcc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
