{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U pip setuptools wheel\n",
    "#! pip install -U 'spacy[cuda12x]'\n",
    "#! python -m spacy download en_core_web_trf\n",
    "#! python -m spacy download en_core_web_sm\n",
    "#! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo que remove pontuacoes, remove stop_words, remove ouliers dos dados do scraper\n",
    "\n",
    "salva um csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baixar CSV DAtaset\n",
    "\n",
    "Para realizar o tratamento de dados a seguir, o IMDB Dataset deve ser baixado, e colocado na pasta raiz do projeto\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie takes place off in fantasy land som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Too sentimental, too pathetic, too slow, too c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are some things in this life we will nev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie was inspired by the brilliant Stir ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For the life of me, I can't understand all the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44422</th>\n",
       "      <td>Uma Thurman returns as the Bride, who this tim...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44423</th>\n",
       "      <td>Quentin Tarantino's \"Kill Bill: Vol. 2\" comple...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44424</th>\n",
       "      <td>Vol 2 is completely different tone then the fi...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44425</th>\n",
       "      <td>This movie is great in that it mixes together ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44426</th>\n",
       "      <td>Kill Bill Volume 2 (directed by Quentin Tarant...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44427 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating\n",
       "0      This movie takes place off in fantasy land som...       1\n",
       "1      Too sentimental, too pathetic, too slow, too c...       1\n",
       "2      There are some things in this life we will nev...       1\n",
       "3      This movie was inspired by the brilliant Stir ...       1\n",
       "4      For the life of me, I can't understand all the...       1\n",
       "...                                                  ...     ...\n",
       "44422  Uma Thurman returns as the Bride, who this tim...      10\n",
       "44423  Quentin Tarantino's \"Kill Bill: Vol. 2\" comple...      10\n",
       "44424  Vol 2 is completely different tone then the fi...      10\n",
       "44425  This movie is great in that it mixes together ...      10\n",
       "44426  Kill Bill Volume 2 (directed by Quentin Tarant...      10\n",
       "\n",
       "[44427 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar o modelo em inglês\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"ner\"])\n",
    "\n",
    "FILE_PATH = \"D:/tcc2/guilherme/3_Data_Processing/data/scrapper_reviews_english_original.csv\" \n",
    "\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "df = df[['review','rating']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linhas de reviews_treated duplicadoss\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_qtd_tokens(x, tokenizer):\n",
    "    tokens = bert_tokenizer.tokenize(x)\n",
    "    return len(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular o tamanho dos textos\n",
    "qtd_tokens = df['review'].apply(lambda x: get_qtd_tokens(x, bert_tokenizer))\n",
    "df = df.assign(qtd_tokens =qtd_tokens )\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['qtd_tokens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Plotar o gráfico\n",
    "def plot_graf_qnt_tokens(series_list):\n",
    "    \n",
    "    mean_length = series_list.mean()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(series_list, edgecolor='k', alpha=0.7, density=True)  # Adicione o argumento density=True\n",
    "    plt.axvline(mean_length, color='r', linestyle='dashed', linewidth=1)\n",
    "    plt.text(mean_length*1.1, plt.ylim()[1]*0.9, f'Média: {mean_length:.2f}', color='r')\n",
    "\n",
    "    # # Adicionar a linha de densidade\n",
    "    # density = gaussian_kde(df['qtd_tokens'])\n",
    "    # xs = np.linspace(df['qtd_tokens'].min(), df['qtd_tokens'].max(), 200)\n",
    "    # plt.plot(xs, density(xs), color='blue')\n",
    "\n",
    "    plt.title('Distribuição do Tamanho dos Textos')\n",
    "    plt.xlabel('Quantidade de Tokens')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.show()\n",
    "\n",
    "plot_graf_qnt_tokens(df['qtd_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remocao de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column):\n",
    "    # Calcular o IQR\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    print(f\"Q1: {Q1}\")\n",
    "    print(f\"Q3: {Q3}\")\n",
    "    print(f\"IQR: {IQR}\")\n",
    "\n",
    "    # Definir os limites para outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    print(f\"Limite inferior: {lower_bound}\")\n",
    "    print(f\"Limite superior: {upper_bound}\")\n",
    "\n",
    "    # Remover outliers\n",
    "    df_without_outliers = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    print(f\"Número de outliers removidos: {len(df) - len(df_without_outliers)}\")\n",
    "\n",
    "    return df_without_outliers\n",
    "\n",
    "\n",
    "print(\"Df com outliers: \", df[\"qtd_tokens\"].size)\n",
    "df_without_outliers = remove_outliers(df, \"qtd_tokens\")\n",
    "print(\"Df sem outliers: \", df_without_outliers[\"review\"].size)\n",
    "df_without_outliers[\"qtd_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graf_qnt_tokens(df_without_outliers['qtd_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max value in df sem outliers:\")\n",
    "df['qtd_tokens'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max value in df com outliers:\")\n",
    "df_without_outliers.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"D:/tcc2/guilherme/3_Data_Processing/data/Scraper_Dataset_english_sem_outliers.csv\"\n",
    "df.to_csv(DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcoes para pre-processamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O tokenizador do Bert já faz isso\n",
    "def remove_extra_spaces(text):\n",
    "    r\"\"\"Remover espacos, quebra de linhas e tabulações do inicio\n",
    "    e fim de frases e ubstituir sequências de espaços\n",
    "    por um espaço\"\"\"\n",
    "\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "\n",
    "# Não usar nos dados do scraper\n",
    "def remove_tags(raw_text):\n",
    "    r\"\"\"Remove tags HTML <.*?>, mas pode remover texto destacado.\"\"\"\n",
    "    cleaned_text = re.sub(re.compile(\"<.*?>\"), \"\", raw_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# O tokenizer bert-base-uncased faz automaticamente\n",
    "def normalize_lowercase(text: str) -> str:\n",
    "    r\"\"\"Converte todas as palavras para forma minuscula\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def remove_stopwords_and_puntuaction(doc: Doc | str):\n",
    "    r\"\"\"Remove pontuacoes,remove stop_words,\n",
    "    e retorna so o texto\"\"\"\n",
    "    if not isinstance(doc, Doc):\n",
    "\n",
    "        doc = nlp(doc)\n",
    "\n",
    "    return \" \".join(\n",
    "        [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    )\n",
    "\n",
    "# funcoes de tratamento spacy\n",
    "def lemmatize_text_remove_stopwords_and_puntuaction(doc: Doc | str):\n",
    "    r\"\"\"Reduz a palavra a lemma, remove pontuacoes,\n",
    "    remove stop_words\"\"\"\n",
    "    if not isinstance(doc, Doc):\n",
    "\n",
    "        doc = nlp(doc)\n",
    "\n",
    "    return \" \".join(\n",
    "        [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# funcoes ilustrativas, são muito ineficientes para serem usadas sozinhas\n",
    "# def remove_punctuation(doc):\n",
    "#     return \" \".join([token.text for token in doc if not token.is_punct])\n",
    "\n",
    "\n",
    "\n",
    "# def remove_stopwords(doc):\n",
    "#     return \" \".join([token.text for token in doc if not token.is_stop])\n",
    "\n",
    "\n",
    "\n",
    "# def lemmatize_text(doc):\n",
    "#     return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def execute_all_trataments(\n",
    "    series_review: pd.Series, FINAL_SPACY_FORMAT: Literal[\"lemma\", \"text\"]\n",
    ") -> List[str]:\n",
    "    if FINAL_SPACY_FORMAT not in [\"lemma\", \"text\"]:\n",
    "        raise ValueError(\"FINAL_SPACY_FORMAT != [lemma | text]\")\n",
    "\n",
    "    reviews_treated = series_review\n",
    "\n",
    "    # reviews_treated = reviews_treated.apply(remove_tags)\n",
    "    ### reviews_treated = reviews_treated.apply(normalize_lowercase)\n",
    "    reviews_treated = reviews_treated.apply(remove_extra_spaces)\n",
    "\n",
    "    len_texts = len(reviews_treated)\n",
    "\n",
    "    docs = list(\n",
    "        tqdm(\n",
    "            nlp.pipe(\n",
    "                reviews_treated,\n",
    "                batch_size=1000,\n",
    "                disable=[\"parser\", \"ner\"],\n",
    "            ),\n",
    "            colour=\"green\",\n",
    "            desc=\"Progresso: \",\n",
    "            total=len_texts,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if FINAL_SPACY_FORMAT == \"lemma\":\n",
    "\n",
    "        reviews_treated = [\n",
    "            lemmatize_text_remove_stopwords_and_puntuaction(doc) for doc in docs\n",
    "        ]\n",
    "\n",
    "    elif FINAL_SPACY_FORMAT == \"text\":\n",
    "\n",
    "        reviews_treated = [remove_stopwords_and_puntuaction(doc) for doc in docs]\n",
    "\n",
    "    reviews_treated = [remove_extra_spaces(review) for review in reviews_treated]\n",
    "\n",
    "    return reviews_treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar as funções de str ao DataFrame\n",
    "# definir como True para saída em forma de token.lemma, ou False para token.text\n",
    "FINAL_SPACY_FORMAT= \"text\" \n",
    "reviews_treated= execute_all_trataments(df[\"review\"],FINAL_SPACY_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"]= reviews_treated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(subset=[\"review\", \"rating\"]).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"review\", \"rating\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['qtd_tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular o tamanho dos textos\n",
    "qtd_tokens = df['review'].apply(lambda x: get_qtd_tokens(x, bert_tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(qtd_tokens=qtd_tokens) \n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['qtd_tokens'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graf_qnt_tokens(df['qtd_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_sem_outliers = remove_outliers(df, \"qtd_tokens\")\n",
    "df_text_sem_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graf_qnt_tokens(df_text_sem_outliers['qtd_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_sem_outliers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_text_sem_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SPACY_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"D:/tcc2/guilherme/3_Data_Processing/data/Scraper_Dataset_treated_{FINAL_SPACY_FORMAT}_sem_outliers.csv\"\n",
    "df.to_csv(DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizacao dos dados após tratamento\n",
    "\n",
    "carregar csv já tratado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATA_PATH = f\"D:/tcc2/guilherme/3_Data_Processing/data/Scraper_Dataset_treated_text_sem_outliers.csv\"\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "\n",
    "# # Concatenar todas as avaliações em uma única string\n",
    "# all_reviews = ' '.join(df['review'])\n",
    "\n",
    "# # Dividir a string em palavras\n",
    "# words = all_reviews.split()\n",
    "\n",
    "# # Contar a frequência de cada palavra\n",
    "# word_counts = collections.Counter(words)\n",
    "\n",
    "# # Exibir as 10 palavras mais comuns\n",
    "# for word, count in word_counts.most_common(-10):\n",
    "#     print(f'Palavra: {word}, Frequência: {count}')\n",
    "\n",
    "# len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Calcular estatísticas básicas\n",
    "# frequencies = list(word_counts.values())\n",
    "# mean_freq = np.mean(frequencies)\n",
    "# median_freq = np.median(frequencies)\n",
    "# min_freq = np.min(frequencies)\n",
    "# max_freq = np.max(frequencies)\n",
    "# std_freq = np.std(frequencies)\n",
    "\n",
    "# print(f\"Média de frequência: {mean_freq}\")\n",
    "# print(f\"Mediana de frequência: {median_freq}\")\n",
    "# print(f\"Frequência mínima: {min_freq}\")\n",
    "# print(f\"Frequência máxima: {max_freq}\")\n",
    "# print(f\"Desvio padrão de frequência: {std_freq}\")\n",
    "\n",
    "# # Calcular o IQR\n",
    "# Q1 = np.percentile(frequencies, 25)\n",
    "# Q3 = np.percentile(frequencies, 75)\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# # Identificar outliers\n",
    "# outliers = [freq for freq in frequencies if freq < Q1 - 1.5 * IQR or freq > Q3 + 1.5 * IQR]\n",
    "\n",
    "# print(f\"Número de outliers: {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# # Calcular o tamanho dos textos\n",
    "# df['qtd_tokens'] = df['review'].apply(len)\n",
    "\n",
    "# # Calcular a média e o desvio padrão\n",
    "# mean_length = df['qtd_tokens'].mean()\n",
    "# std_length = df['qtd_tokens'].std()\n",
    "\n",
    "# # Definir o limite para remoção de outliers (por exemplo, 3 desvios padrão)\n",
    "# threshold_min = mean_length - 3 * std_length\n",
    "# threshold_max = mean_length + 3 * std_length\n",
    "\n",
    "# # Filtrar os textos dentro do limite\n",
    "# df_filtered = df[(df['qtd_tokens'] >= threshold_min) & (df['qtd_tokens'] <= threshold_max)]\n",
    "\n",
    "# # Calcular a nova média\n",
    "# mean_length_filtered = df_filtered['qtd_tokens'].mean()\n",
    "\n",
    "# # Plotar o gráfico sem outliers\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(df_filtered['qtd_tokens'], bins=30, edgecolor='k', alpha=0.7)\n",
    "# plt.axvline(mean_length_filtered, color='r', linestyle='dashed', linewidth=1)\n",
    "# plt.text(mean_length_filtered*1.1, plt.ylim()[1]*0.9, f'Média: {mean_length_filtered:.2f}', color='r')\n",
    "# plt.title('Distribuição do Tamanho dos Textos (Sem Outliers)')\n",
    "# plt.xlabel('Tamanho do Texto')\n",
    "# plt.ylabel('Frequência')\n",
    "# plt.show()\n",
    "\n",
    "# result_string = (\n",
    "#     f\"Distribuição do Tamanho dos Textos (Sem Outliers)\\n\"\n",
    "#     f\"Média do tamanho dos textos: {mean_length_filtered:.2f}\\n\"\n",
    "#     f\"Limite inferior para remoção de outliers: {threshold_min:.2f}\\n\"\n",
    "#     f\"Limite superior para remoção de outliers: {threshold_max:.2f}\\n\"\n",
    "#     f\"Total de textos considerados: {len(df_filtered)}\"\n",
    "# )\n",
    "\n",
    "# print(result_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está um exemplo ajustado usando quantis para remover outliers:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
